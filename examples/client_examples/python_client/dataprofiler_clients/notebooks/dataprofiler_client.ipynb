{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import dataprofiler as dp\n",
    "\n",
    "sys.path.insert(0, os.path.abspath( '../../../../../clients/python_client'))\n",
    "import fma_connect  # noqa: E402\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils import intialize_logger, numpify_array, jsonify_array, print_results\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from dataprofiler_utils.generation_scripts import generate_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global settings\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "try: logger\n",
    "except NameError:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    intialize_logger(logger, \"logfile.log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Service contact variables\n",
    "federated_model_id = 4\n",
    "url = \"http://127.0.0.1:8000\"\n",
    "uuid_storage_path = \"./uuid_temp.txt\"\n",
    "\n",
    "# Model training params\n",
    "num_epochs = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for generation of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "entity_names = [\"COOKIE\", \"MAC_ADDRESS\", \"SSN\", \"DATETIME\"]\n",
    "\n",
    "entity_name = random.choice(entity_names)\n",
    "num_of_train_entities = 1\n",
    "num_of_val_entities = 1\n",
    "validation_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the model you wish to use with the service (Dataprofiler in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_arch = dp.DataLabeler(labeler_type='unstructured',\n",
    "                            trainable=True)\n",
    "model_arch.set_labels({\n",
    "    \"PAD\": 0,\n",
    "    \"UNKNOWN\": 1,\n",
    "    \"DATETIME\": 2,\n",
    "    \"COOKIE\": 3,\n",
    "    \"MAC_ADDRESS\": 4,\n",
    "    \"SSN\": 5,\n",
    "})\n",
    "model_arch.model._reconstruct_model()\n",
    "# Setting post process params for human-readable format\n",
    "model_arch.set_params({ 'postprocessor': { 'output_format': 'ner', 'use_word_level_argmax': True } })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(uuid_storage_path) as f:\n",
    "        uuid = f.read()\n",
    "        logger.info(f\"Connecting with {uuid} as UUID\")\n",
    "        client = fma_connect.WebClient(federated_model_id=federated_model_id, url=url, uuid=uuid)\n",
    "except FileNotFoundError:\n",
    "    logger.info(f\"Connecting without UUID\")\n",
    "    client = fma_connect.WebClient(federated_model_id=federated_model_id, url=url)\n",
    "finally:\n",
    "    client.register()\n",
    "    uuid = client.uuid\n",
    "    with open(uuid_storage_path, \"w+\") as f:\n",
    "        f.write(uuid)\n",
    "    logger.info(f\"{uuid} stored as UUID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull weights from service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_agg = client.check_for_new_model_aggregate(update_after=0)\n",
    "if not model_agg:\n",
    "    init_weights = client.get_current_artifact()['values']\n",
    "else:\n",
    "    init_weights = model_agg['result']\n",
    "\n",
    "numpify_array(init_weights)\n",
    "model_arch.model._model.set_weights(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generate validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset_split = [\n",
    "    generate_sample(entity, num_of_val_entities, validation_seed)\n",
    "    for entity in entity_names\n",
    "]\n",
    "val_dataset = {\n",
    "    k: [\n",
    "        item for dic in val_dataset_split\n",
    "        for item in dic[k]]\n",
    "    for k in val_dataset_split[0]\n",
    "}\n",
    "pprint(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "training_idx = 0\n",
    "while True:\n",
    "    logger.info(f\"Training loop: {training_idx}\")\n",
    "\n",
    "    logger.info(\"Generating training dataset\")\n",
    "    train_dataset = generate_sample(entity_name, num_of_train_entities)\n",
    "\n",
    "    logger.info(\"Training initiated\")\n",
    "    model_arch.fit(x=train_dataset['text'], y=train_dataset['entities'], epochs=num_epochs)\n",
    "    logger.info(\"Training complete\")\n",
    "\n",
    "\n",
    "    # Run validation with trained weights\n",
    "    logger.info(\"Eval after local training started...\")\n",
    "    predictions = model_arch.predict(val_dataset[\"text\"])\n",
    "    logger.info(\"Eval after local training complete!\")\n",
    "    print_results(val_dataset['text'], predictions, logger)\n",
    "\n",
    "    # Data preparation for sending to service API\n",
    "    weights = model_arch.model._model.get_weights()\n",
    "    jsonify_array(weights)\n",
    "\n",
    "    # Send data to service\n",
    "    client.send_update(weights)\n",
    "    logger.info(\"Weights updates sent\")\n",
    "\n",
    "    # Check for model weights updates from service\n",
    "    logger.info(\"Checking for service model update\")\n",
    "    model_agg = client.check_for_new_model_aggregate()\n",
    "    while not model_agg:\n",
    "        logger.info(\"Received None response...\")\n",
    "        time.sleep(5)\n",
    "        model_agg = client.check_for_new_model_aggregate()\n",
    "    logger.info(\"Response received.\")\n",
    "\n",
    "    # Convert service response to loadable weights\n",
    "    numpify_array(model_agg['result'])\n",
    "    model_arch.model._model.set_weights(model_agg['result'])\n",
    "    logger.info(\"New model weights set\")\n",
    "\n",
    "    # Run validation with new weights\n",
    "    logger.info(\"Aggregated model weights eval started...\")\n",
    "    predictions = model_arch.predict(val_dataset[\"text\"])\n",
    "    logger.info(\"Aggregated model weights eval complete!\")\n",
    "    print_results(val_dataset['text'], predictions, logger)\n",
    "\n",
    "    training_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
